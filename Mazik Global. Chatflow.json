{
  "nodes": [
    {
      "id": "htmlToMarkdownTextSplitter_0",
      "position": {
        "x": 99.6843960291213,
        "y": -222.10678500708696
      },
      "type": "customNode",
      "data": {
        "id": "htmlToMarkdownTextSplitter_0",
        "label": "HtmlToMarkdown Text Splitter",
        "version": 1,
        "name": "htmlToMarkdownTextSplitter",
        "type": "HtmlToMarkdownTextSplitter",
        "baseClasses": [
          "HtmlToMarkdownTextSplitter",
          "MarkdownTextSplitter",
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Converts Html to Markdown and then split your content into documents based on the Markdown headers",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "default": 1000,
            "optional": true,
            "id": "htmlToMarkdownTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "optional": true,
            "id": "htmlToMarkdownTextSplitter_0-input-chunkOverlap-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": 1000,
          "chunkOverlap": "300"
        },
        "outputAnchors": [
          {
            "id": "htmlToMarkdownTextSplitter_0-output-htmlToMarkdownTextSplitter-HtmlToMarkdownTextSplitter|MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "htmlToMarkdownTextSplitter",
            "label": "HtmlToMarkdownTextSplitter",
            "description": "Converts Html to Markdown and then split your content into documents based on the Markdown headers",
            "type": "HtmlToMarkdownTextSplitter | MarkdownTextSplitter | RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 376,
      "selected": false,
      "positionAbsolute": {
        "x": 99.6843960291213,
        "y": -222.10678500708696
      },
      "dragging": false
    },
    {
      "id": "cheerioWebScraper_0",
      "position": {
        "x": 515.1829667328165,
        "y": -404.6002748847884
      },
      "type": "customNode",
      "data": {
        "id": "cheerioWebScraper_0",
        "label": "Cheerio Web Scraper",
        "version": 1.1,
        "name": "cheerioWebScraper",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from webpages",
        "inputParams": [
          {
            "label": "URL",
            "name": "url",
            "type": "string",
            "id": "cheerioWebScraper_0-input-url-string"
          },
          {
            "label": "Get Relative Links Method",
            "name": "relativeLinksMethod",
            "type": "options",
            "description": "Select a method to retrieve relative links",
            "options": [
              {
                "label": "Web Crawl",
                "name": "webCrawl",
                "description": "Crawl relative links from HTML URL"
              },
              {
                "label": "Scrape XML Sitemap",
                "name": "scrapeXMLSitemap",
                "description": "Scrape relative links from XML sitemap URL"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "cheerioWebScraper_0-input-relativeLinksMethod-options"
          },
          {
            "label": "Get Relative Links Limit",
            "name": "limit",
            "type": "number",
            "optional": true,
            "default": "10",
            "additionalParams": true,
            "description": "Only used when \"Get Relative Links Method\" is selected. Set 0 to retrieve all relative links, default limit is 10.",
            "warning": "Retrieving all links might take long time, and all links will be upserted again if the flow's state changed (eg: different URL, chunk size, etc)",
            "id": "cheerioWebScraper_0-input-limit-number"
          },
          {
            "label": "Selector (CSS)",
            "name": "selector",
            "type": "string",
            "description": "Specify a CSS selector to select the content to be extracted",
            "optional": true,
            "additionalParams": true,
            "id": "cheerioWebScraper_0-input-selector-string"
          },
          {
            "label": "Metadata",
            "name": "metadata",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "cheerioWebScraper_0-input-metadata-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "cheerioWebScraper_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "url": "https://mazikglobal.com/",
          "textSplitter": "{{htmlToMarkdownTextSplitter_0.data.instance}}",
          "relativeLinksMethod": "",
          "limit": "10",
          "selector": "",
          "metadata": ""
        },
        "outputAnchors": [
          {
            "id": "cheerioWebScraper_0-output-cheerioWebScraper-Document",
            "name": "cheerioWebScraper",
            "label": "Document",
            "description": "Load data from webpages",
            "type": "Document"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 425,
      "selected": false,
      "positionAbsolute": {
        "x": 515.1829667328165,
        "y": -404.6002748847884
      },
      "dragging": false
    },
    {
      "id": "googlePaLMEmbeddings_0",
      "position": {
        "x": 521.7005913713057,
        "y": 287.89734295470356
      },
      "type": "customNode",
      "data": {
        "id": "googlePaLMEmbeddings_0",
        "label": "Google PaLM Embeddings",
        "version": 2,
        "name": "googlePaLMEmbeddings",
        "type": "GooglePaLMEmbeddings",
        "baseClasses": [
          "GooglePaLMEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "Google MakerSuite PaLM API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleMakerSuite"
            ],
            "id": "googlePaLMEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "models/embedding-gecko-001",
            "id": "googlePaLMEmbeddings_0-input-modelName-asyncOptions"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "models/embedding-gecko-001"
        },
        "outputAnchors": [
          {
            "id": "googlePaLMEmbeddings_0-output-googlePaLMEmbeddings-GooglePaLMEmbeddings|Embeddings",
            "name": "googlePaLMEmbeddings",
            "label": "GooglePaLMEmbeddings",
            "description": "Google MakerSuite PaLM API to generate embeddings for a given text",
            "type": "GooglePaLMEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 370,
      "selected": false,
      "positionAbsolute": {
        "x": 521.7005913713057,
        "y": 287.89734295470356
      },
      "dragging": false
    },
    {
      "id": "chatGooglePaLM_0",
      "position": {
        "x": 927.4227251172671,
        "y": -508.23050663676895
      },
      "type": "customNode",
      "data": {
        "id": "chatGooglePaLM_0",
        "label": "ChatGooglePaLM",
        "version": 3,
        "name": "chatGooglePaLM",
        "type": "ChatGooglePaLM",
        "baseClasses": [
          "ChatGooglePaLM",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google MakerSuite PaLM large language models using the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleMakerSuite"
            ],
            "id": "chatGooglePaLM_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "models/chat-bison-001",
            "id": "chatGooglePaLM_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "description": "Controls the randomness of the output.\nValues can range from [0.0,1.0], inclusive. A value closer to 1.0 will produce responses that are more varied and creative, while a value closer to 0.0 will typically result in more straightforward responses from the model.",
            "id": "chatGooglePaLM_0-input-temperature-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "description": "Top-p changes how the model selects tokens for output.\nTokens are selected from most probable to least until the sum of their probabilities equals the top-p value.\nFor example, if tokens A, B, and C have a probability of .3, .2, and .1 and the top-p value is .5, then the model will select either A or B as the next token (using temperature).",
            "id": "chatGooglePaLM_0-input-topP-number"
          },
          {
            "label": "Top-k",
            "name": "topK",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "description": "Top-k changes how the model selects tokens for output.\nA top-k of 1 means the selected token is the most probable among all tokens in the model vocabulary (also called greedy decoding), while a top-k of 3 means that the next token is selected from among the 3 most probable tokens (using temperature).",
            "id": "chatGooglePaLM_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGooglePaLM_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "models/chat-bison-001",
          "temperature": 0.7,
          "topP": "",
          "topK": ""
        },
        "outputAnchors": [
          {
            "id": "chatGooglePaLM_0-output-chatGooglePaLM-ChatGooglePaLM|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGooglePaLM",
            "label": "ChatGooglePaLM",
            "description": "Wrapper around Google MakerSuite PaLM large language models using the Chat endpoint",
            "type": "ChatGooglePaLM | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 572,
      "selected": false,
      "positionAbsolute": {
        "x": 927.4227251172671,
        "y": -508.23050663676895
      },
      "dragging": false
    },
    {
      "id": "memoryVectorStore_0",
      "position": {
        "x": 935.5697559153786,
        "y": 262.15272563267075
      },
      "type": "customNode",
      "data": {
        "id": "memoryVectorStore_0",
        "label": "In-Memory Vector Store",
        "version": 1,
        "name": "memoryVectorStore",
        "type": "Memory",
        "baseClasses": [
          "Memory",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "In-memory vectorstore that stores embeddings and does an exact, linear search for the most similar embeddings.",
        "inputParams": [
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "optional": true,
            "id": "memoryVectorStore_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "memoryVectorStore_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "memoryVectorStore_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "document": [
            "{{cheerioWebScraper_0.data.instance}}"
          ],
          "embeddings": "{{googlePaLMEmbeddings_0.data.instance}}",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Memory Retriever",
                "description": "",
                "type": "Memory | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "memoryVectorStore_0-output-vectorStore-Memory|VectorStore",
                "name": "vectorStore",
                "label": "Memory Vector Store",
                "description": "",
                "type": "Memory | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "retriever"
        },
        "selected": false
      },
      "width": 300,
      "height": 405,
      "selected": false,
      "positionAbsolute": {
        "x": 935.5697559153786,
        "y": 262.15272563267075
      },
      "dragging": false
    },
    {
      "id": "conversationalRetrievalQAChain_0",
      "position": {
        "x": 1492.6952677663464,
        "y": -163.12228202875843
      },
      "type": "customNode",
      "data": {
        "id": "conversationalRetrievalQAChain_0",
        "label": "Conversational Retrieval QA Chain",
        "version": 3,
        "name": "conversationalRetrievalQAChain",
        "type": "ConversationalRetrievalQAChain",
        "baseClasses": [
          "ConversationalRetrievalQAChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
        "inputParams": [
          {
            "label": "Return Source Documents",
            "name": "returnSourceDocuments",
            "type": "boolean",
            "optional": true,
            "id": "conversationalRetrievalQAChain_0-input-returnSourceDocuments-boolean"
          },
          {
            "label": "Rephrase Prompt",
            "name": "rephrasePrompt",
            "type": "string",
            "description": "Using previous chat history, rephrase question into a standalone question",
            "warning": "Prompt must include input variables: {chat_history} and {question}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
            "id": "conversationalRetrievalQAChain_0-input-rephrasePrompt-string"
          },
          {
            "label": "Response Prompt",
            "name": "responsePrompt",
            "type": "string",
            "description": "Taking the rephrased question, search for answer from the provided context",
            "warning": "Prompt must include input variable: {context}",
            "rows": 4,
            "additionalParams": true,
            "optional": true,
            "default": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
            "id": "conversationalRetrievalQAChain_0-input-responsePrompt-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "conversationalRetrievalQAChain_0-input-model-BaseChatModel"
          },
          {
            "label": "Vector Store Retriever",
            "name": "vectorStoreRetriever",
            "type": "BaseRetriever",
            "id": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseMemory",
            "optional": true,
            "description": "If left empty, a default BufferMemory will be used",
            "id": "conversationalRetrievalQAChain_0-input-memory-BaseMemory"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "conversationalRetrievalQAChain_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{chatGooglePaLM_0.data.instance}}",
          "vectorStoreRetriever": "{{memoryVectorStore_0.data.instance}}",
          "memory": "",
          "returnSourceDocuments": "",
          "rephrasePrompt": "Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n\nChat History:\n{chat_history}\nFollow Up Input: {question}\nStandalone Question:",
          "responsePrompt": "I want you to act as a document that I am having a conversation with. Your name is \"AI Assistant\". Using the provided context, answer the user's question to the best of your ability using the resources provided.\nIf there is nothing in the context relevant to the question at hand, just say \"Hmm, I'm not sure\" and stop after that. Refuse to answer any question not about the info. Never break character.\n------------\n{context}\n------------\nREMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm not sure\". Don't try to make up an answer. Never break character.",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "conversationalRetrievalQAChain_0-output-conversationalRetrievalQAChain-ConversationalRetrievalQAChain|BaseChain|Runnable",
            "name": "conversationalRetrievalQAChain",
            "label": "ConversationalRetrievalQAChain",
            "description": "Document QA - built on RetrievalQAChain to provide a chat history component",
            "type": "ConversationalRetrievalQAChain | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 530,
      "selected": false,
      "positionAbsolute": {
        "x": 1492.6952677663464,
        "y": -163.12228202875843
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "htmlToMarkdownTextSplitter_0",
      "sourceHandle": "htmlToMarkdownTextSplitter_0-output-htmlToMarkdownTextSplitter-HtmlToMarkdownTextSplitter|MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "cheerioWebScraper_0",
      "targetHandle": "cheerioWebScraper_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "htmlToMarkdownTextSplitter_0-htmlToMarkdownTextSplitter_0-output-htmlToMarkdownTextSplitter-HtmlToMarkdownTextSplitter|MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-cheerioWebScraper_0-cheerioWebScraper_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "cheerioWebScraper_0",
      "sourceHandle": "cheerioWebScraper_0-output-cheerioWebScraper-Document",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-document-Document",
      "type": "buttonedge",
      "id": "cheerioWebScraper_0-cheerioWebScraper_0-output-cheerioWebScraper-Document-memoryVectorStore_0-memoryVectorStore_0-input-document-Document"
    },
    {
      "source": "googlePaLMEmbeddings_0",
      "sourceHandle": "googlePaLMEmbeddings_0-output-googlePaLMEmbeddings-GooglePaLMEmbeddings|Embeddings",
      "target": "memoryVectorStore_0",
      "targetHandle": "memoryVectorStore_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "googlePaLMEmbeddings_0-googlePaLMEmbeddings_0-output-googlePaLMEmbeddings-GooglePaLMEmbeddings|Embeddings-memoryVectorStore_0-memoryVectorStore_0-input-embeddings-Embeddings"
    },
    {
      "source": "memoryVectorStore_0",
      "sourceHandle": "memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever",
      "type": "buttonedge",
      "id": "memoryVectorStore_0-memoryVectorStore_0-output-retriever-Memory|VectorStoreRetriever|BaseRetriever-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-vectorStoreRetriever-BaseRetriever"
    },
    {
      "source": "chatGooglePaLM_0",
      "sourceHandle": "chatGooglePaLM_0-output-chatGooglePaLM-ChatGooglePaLM|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "conversationalRetrievalQAChain_0",
      "targetHandle": "conversationalRetrievalQAChain_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGooglePaLM_0-chatGooglePaLM_0-output-chatGooglePaLM-ChatGooglePaLM|BaseChatModel|BaseLanguageModel|Runnable-conversationalRetrievalQAChain_0-conversationalRetrievalQAChain_0-input-model-BaseChatModel"
    }
  ]
}